{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dataset.sequence import SkeletonClusteredSequence, ClusteredSequence\n",
    "import pickle as pkl\n",
    "import mxnet as mx\n",
    "from tqdm import tqdm\n",
    "from copy import copy\n",
    "\n",
    "with open('clustered_sequences.pkl', 'rb') as file:\n",
    "    sequences = pkl.load(file)\n",
    "\n",
    "with open('skeleton_sequences.pkl', 'rb') as file:\n",
    "    skeletons = pkl.load(file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "1692"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered_skeleton_sequences = []\n",
    "for sk_seq in skeletons:\n",
    "    for seq in sequences:\n",
    "        if sk_seq.name_pattern == seq.name_pattern and sk_seq.start_frame == seq.gt['frame'].min():\n",
    "            clustered_skeleton_sequences.append(SkeletonClusteredSequence(seq, sk_seq))\n",
    "            break\n",
    "len(clustered_skeleton_sequences)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "from utils.missing_data import remove_ellipsis\n",
    "import numpy as np\n",
    "from utils.normalizers import skeleton_normalizer\n",
    "\n",
    "\n",
    "class SinglePersonSequenceHandler:\n",
    "    def __init__(self, seq: SkeletonClusteredSequence):\n",
    "        self.seq = seq\n",
    "\n",
    "    def get_person_num(self):\n",
    "        return len(self.seq.person_features)\n",
    "\n",
    "    def get_person_ids(self):\n",
    "        return list(self.seq.person_features.keys())\n",
    "\n",
    "    def get_single_person_attributes(self, person_id):\n",
    "        array_index = self.get_person_ids().index(person_id)\n",
    "        klass = self.seq.cluster_labels[array_index]\n",
    "        skeleton_seq, confidence_seq, classes_seq, bboxes_seq, scores_seq = self._get_skeleton_seq(person_id)\n",
    "        return skeleton_seq, confidence_seq, classes_seq, bboxes_seq, scores_seq, klass\n",
    "\n",
    "    def get_single_person_as_train_record(self, person_id):\n",
    "        array_index = self.get_person_ids().index(person_id)\n",
    "        klass = self.seq.cluster_labels[array_index]\n",
    "        skeleton_seq = []\n",
    "        for skeleton_iter, person_ids in zip(self.seq.skeleton_seq.skeletons_seq, self.seq.skeleton_seq.person_ids):\n",
    "            if person_id not in person_ids:\n",
    "                skeleton_seq.append(...)\n",
    "                continue\n",
    "            person_idx = np.where(person_ids == float(person_id))[0]\n",
    "            skeleton_seq.append(skeleton_normalizer(skeleton_iter[person_idx]))\n",
    "        filled_skeletons =remove_ellipsis(skeleton_seq)\n",
    "\n",
    "\n",
    "        return filled_skeletons, klass\n",
    "\n",
    "    def _get_skeleton_seq(self, person_id):\n",
    "        skeleton_seq = []\n",
    "        confidence_seq = []\n",
    "        classes_seq = []\n",
    "        bboxes_seq = []\n",
    "        scores_seq = []\n",
    "        for skeleton_iter, confidence_iter, classes_iter, bboxes_iter, scores_iter, person_ids in zip(self.seq.skeleton_seq.skeletons_seq,\n",
    "                                                                             self.seq.skeleton_seq.confidence_seq,\n",
    "                                                                             self.seq.skeleton_seq.classes_seq,\n",
    "                                                                             self.seq.skeleton_seq.bboxes_seq,\n",
    "                                                                             self.seq.skeleton_seq.scores_seq,\n",
    "                                                                             self.seq.skeleton_seq.person_ids):\n",
    "            if person_id not in person_ids:\n",
    "                skeleton_seq.append(...)\n",
    "                confidence_seq.append(...)\n",
    "                classes_seq.append(...)\n",
    "                bboxes_seq.append(...)\n",
    "                scores_seq.append(...)\n",
    "                continue\n",
    "            person_idx = np.where(person_ids == float(person_id))[0]\n",
    "            skeleton_seq.append(skeleton_iter[person_idx])\n",
    "            confidence_seq.append(confidence_iter[person_idx])\n",
    "            classes_seq.append(classes_iter[0][person_idx])\n",
    "            bboxes_seq.append(bboxes_iter[0][person_idx])\n",
    "            scores_seq.append(scores_iter[0][person_idx])\n",
    "        return remove_ellipsis(skeleton_seq), remove_ellipsis(confidence_seq), remove_ellipsis(\n",
    "            classes_seq), remove_ellipsis(bboxes_seq), remove_ellipsis(scores_seq)\n",
    "\n",
    "\n",
    "handler = SinglePersonSequenceHandler(clustered_skeleton_sequences[0])\n",
    "# skeleton, confidence, classes, bboxes, scores, klass = handler.get_single_person_attributes(4)\n",
    "skeleton, klass = handler.get_single_person_as_train_record(4)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import gluoncv\n",
    "import cv2\n",
    "#\n",
    "# seq = sequences[0]\n",
    "# gt = seq.gt\n",
    "# start_frame = gt['frame'].min()\n",
    "# end_frame = gt['frame'].max()\n",
    "# is_in_frames = ((gt['frame'] >= start_frame) & (gt['frame'] <= end_frame))\n",
    "#\n",
    "# for frame in tqdm(range(start_frame, end_frame + 1)):\n",
    "#     img = cv2.imread(seq.name_pattern.format(frame=frame))\n",
    "#     ax = gluoncv.utils.viz.cv_plot_keypoints(img,\n",
    "#                                             # skeleton_normalizer(skeleton[frame - start_frame]),\n",
    "#                                              skeleton[frame - start_frame],\n",
    "#                                              confidence[frame - start_frame],\n",
    "#                                              np.array([classes[frame - start_frame]]), np.array([bboxes[frame - start_frame]]),\n",
    "#                                              np.array([scores[frame - start_frame]]),\n",
    "#                                              box_thresh=0.5, keypoint_thresh=0.0)\n",
    "#     # labels=det_labels, colors=colors)\n",
    "#     cv2.imshow('frame', ax)\n",
    "#     cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "# cv2.waitKey(1)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1692/1692 [00:18<00:00, 90.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "((32, 17, 2), 6)"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "for seq in tqdm(clustered_skeleton_sequences):\n",
    "    handler = SinglePersonSequenceHandler(seq)\n",
    "    for person_id in handler.get_person_ids():\n",
    "        skeleton, klass = handler.get_single_person_as_train_record(person_id)\n",
    "        X.append(np.squeeze(np.array(skeleton)))\n",
    "        y.append(klass)\n",
    "print(len(X           ))\n",
    "X[0].shape, y[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "with open('single_X.pkl', 'wb') as file:\n",
    "    pkl.dump(                           X, file)\n",
    "\n",
    "with open('single_y.pkl', 'wb') as file:\n",
    "    pkl.dump(y, file)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
